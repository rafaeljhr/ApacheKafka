##Using Helm to Install Applications
-------------------
#Helm is a package manager for Kubernetes that helps define, install, and upgrade 
#even the most complex Kubernetes applications.

#Setup Helm

$
wget https://get.helm.sh/helm-v3.6.3-linux-amd64.tar.gz
tar -xvf helm-v3.6.3-linux-amd64.tar.gz
cd linux-amd64/
sudo mv helm /usr/local/bin
helm version
<shows>version.BuildInfo{Version:"v3.6.3", GitCommit:"d506314abfb5d21419df8c7e7e68012379db2354", GitTreeState:"clean", GoVersion:"go1.16.5"}

#Install Confluent Kafka Platform in Amazon EKS Using Helm Chart
-----------------
#Confluent Platform is a streaming platform for large-scale distributed environments, 
#and is built on Apache Kafka. Confluent Platform enables all your interfaces and data systems
#to be connected

#Confluentâ€™s Helm Chart can be used to install the complete suite of Confluent Kafka Platform 
#onto Kubernetes/EKS thus greatly simplifying the usage of Kafka components

#Cloning the Confluent Helm Chart Repo
$helm repo add confluent https://confluentinc.github.io/cp-helm-charts/
$helm repo update

#After the Confluent Platform Helm Chart installed, by default, 
these components are to be setup on EKS.
-A Zookeeper cluster of three Pods(StatefulSet)
-A Kafka cluster of 3 brokers on three Pods (StatefulSet)
-One Confluent Schema Registry instance in one Pod(Deployment)
-One Confluent REST Proxy instance in one Pod (Deployment)
-One Kafka Connect worker in one Pod(Deployment)
-One KSQL server in one Pod.(Deployment)

$helm install confluent/cp-helm-charts -g

----sampleoutput-----
NAME: cp-helm-charts-1628681515
LAST DEPLOYED: Wed Aug 11 11:31:56 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
## ------------------------------------------------------
## Zookeeper
## ------------------------------------------------------
Connection string for Confluent Kafka:
  cp-helm-charts-1628681515-cp-zookeeper-0.cp-helm-charts-1628681515-cp-zookeeper-headless:2181,cp-helm-charts-1628681515-cp-zookeeper-1.cp-helm-charts-1628681515-cp-zookeeper-headless:2181,...

To connect from a client pod:

1. Deploy a zookeeper client pod with configuration:

    apiVersion: v1
    kind: Pod
    metadata:
      name: zookeeper-client
      namespace: default
    spec:
      containers:
      - name: zookeeper-client
        image: confluentinc/cp-zookeeper:6.1.0
        command:
          - sh
          - -c
          - "exec tail -f /dev/null"

2. Log into the Pod

  kubectl exec -it zookeeper-client -- /bin/bash

3. Use zookeeper-shell to connect in the zookeeper-client Pod:

  zookeeper-shell cp-helm-charts-1628681515-cp-zookeeper:2181

4. Explore with zookeeper commands, for example:

  # Gives the list of active brokers
  ls /brokers/ids

  # Gives the list of topics
  ls /brokers/topics

  # Gives more detailed information of the broker id '0'
  get /brokers/ids/0## ------------------------------------------------------
## Kafka
## ------------------------------------------------------
To connect from a client pod:

1. Deploy a kafka client pod with configuration:

    apiVersion: v1
    kind: Pod
    metadata:
      name: kafka-client
      namespace: default
    spec:
      containers:
      - name: kafka-client
        image: confluentinc/cp-enterprise-kafka:6.1.0
        command:
          - sh
          - -c
          - "exec tail -f /dev/null"

2. Log into the Pod

  kubectl exec -it kafka-client -- /bin/bash

3. Explore with kafka commands:

  # Create the topic
  kafka-topics --zookeeper cp-helm-charts-1628681515-cp-zookeeper-headless:2181 --topic cp-helm-charts-1628681515-topic --create --partitions 1 --replication-factor 1 --if-not-exists

  # Create a message
  MESSAGE="`date -u`"

  # Produce a test message to the topic
  echo "$MESSAGE" | kafka-console-producer --broker-list cp-helm-charts-1628681515-cp-kafka-headless:9092 --topic cp-helm-charts-1628681515-topic

  # Consume a test message from the topic
  kafka-console-consumer --bootstrap-server cp-helm-charts-1628681515-cp-kafka-headless:9092 --topic cp-helm-charts-1628681515-topic --from-beginning --timeout-ms 2000 --max-messages 1 | grep "$MESSAGE
------------------
#Checking Pods created and running
$kubectl get pods | awk {'print $1" "$3'} | column -t
---------sampleoutput------
cp-helm-charts-1628681515-cp-control-center-6c5fc97d-j2dsz     Running
cp-helm-charts-1628681515-cp-kafka-0                           Running
cp-helm-charts-1628681515-cp-kafka-1                           Running
cp-helm-charts-1628681515-cp-kafka-2                           Pending
cp-helm-charts-1628681515-cp-kafka-connect-8666894fd8-4pc9w    Running
cp-helm-charts-1628681515-cp-kafka-rest-685f6747bf-r5bwj       Running
cp-helm-charts-1628681515-cp-ksql-server-6f8796f8dd-5rqfx      Running
cp-helm-charts-1628681515-cp-schema-registry-57965c4bdd-t57gc  Running
cp-helm-charts-1628681515-cp-zookeeper-0                       Running
cp-helm-charts-1628681515-cp-zookeeper-1                       Running
cp-helm-charts-1628681515-cp-zookeeper-2                       ContainerCreating
------------------------
#Two StatefulSets created for Zookeeper cluster and Kafka cluster.
$ kubectl get statefulset
NAME                                     READY   AGE
cp-helm-charts-1628681515-cp-kafka       3/3     2m38s
cp-helm-charts-1628681515-cp-zookeeper   3/3     2m38s

#For StatefulSets, each Pod has Persistent Volume Claim(PVC) created in AWS
$kubectl get pvc | awk {'print $1" "$2" "$4'} | column -t
NAME                                                 STATUS  CAPACITY
datadir-0-cp-helm-charts-1628681515-cp-kafka-0       Bound   5Gi
datadir-0-cp-helm-charts-1628681515-cp-kafka-1       Bound   5Gi
datadir-0-cp-helm-charts-1628681515-cp-kafka-2       Bound   5Gi
datadir-cp-helm-charts-1628681515-cp-zookeeper-0     Bound   10Gi
datadir-cp-helm-charts-1628681515-cp-zookeeper-1     Bound   10Gi
datadir-cp-helm-charts-1628681515-cp-zookeeper-2     Bound   10Gi
datalogdir-cp-helm-charts-1628681515-cp-zookeeper-0  Bound   10Gi
datalogdir-cp-helm-charts-1628681515-cp-zookeeper-1  Bound   10Gi
datalogdir-cp-helm-charts-1628681515-cp-zookeeper-2  Bound   10Gi

#Deployments are created for Confluent Connectors, 
#Confluent REST Proxy, Confluent KSQL, Confluent Schema Registry
$kubectl get deployments | awk {'print $1" "$5'} | column -t
------------sampleoutput---------
NAME                                          AGE
cp-helm-charts-1628681515-cp-control-center   3m32s
cp-helm-charts-1628681515-cp-kafka-connect    3m32s
cp-helm-charts-1628681515-cp-kafka-rest       3m32s
cp-helm-charts-1628681515-cp-ksql-server      3m32s
cp-helm-charts-1628681515-cp-schema-registry  3m32s
--------------------------------
#ClusterIP Services created.
-------------------sampleoutput----------------
$ kubectl get svc | awk {'print $1" "$2" "$3" "$5'} | column -t 
NAME                                             TYPE       CLUSTER-IP      PORT(S)
cp-helm-charts-1628681515-cp-control-center      ClusterIP  10.100.245.84   9021/TCP
cp-helm-charts-1628681515-cp-kafka               ClusterIP  10.100.156.213  9092/TCP,5556/TCP
cp-helm-charts-1628681515-cp-kafka-connect       ClusterIP  10.100.19.11    8083/TCP,5556/TCP
cp-helm-charts-1628681515-cp-kafka-headless      ClusterIP  None            9092/TCP
cp-helm-charts-1628681515-cp-kafka-rest          ClusterIP  10.100.186.212  8082/TCP,5556/TCP
cp-helm-charts-1628681515-cp-ksql-server         ClusterIP  10.100.249.135  8088/TCP,5556/TCP
cp-helm-charts-1628681515-cp-schema-registry     ClusterIP  10.100.234.15   8081/TCP,5556/TCP
cp-helm-charts-1628681515-cp-zookeeper           ClusterIP  10.100.19.149   2181/TCP,5556/TCP
cp-helm-charts-1628681515-cp-zookeeper-headless  ClusterIP  None            2888/TCP,3888/TCP
kubernetes                                       ClusterIP  10.100.0.1      443/TCP
------------------------------------------
#Creating a Pod with Zookeeper Client
#creating zookeeper-client
#refer the directory 'zookeeper-client' and use it OR

#create a directory 
$mkdir zookeeper-client
$cd zookeeper-client
#create a file
$vi deployment.yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: zookeeper-client
  namespace: default
spec:
 containers:
 - name: zookeeper-client
   image: confluentinc/cp-zookeeper:5.0.1
   command:
     - sh
     - -c
     - "exec tail -f /dev/null"
---
#After deployment.yaml file is ready..

<while being in zookeeper-client directory>
$kubectl apply -f deployment.yaml

$kubectl get pods

#login into zookeeper-client pod
$kubectl exec -it zookeeper-client -- /bin/bash

within the pod
>zookeeper-shell zookeeper-client:2181
>ls /brokers/ids

#creating kafka-client pod
#refer the directory 'kafka-client' and use it OR

$mkdir kafka-client
$cd  kafka-client
#create a file 
$vi deployment.yaml

---
apiVersion: v1
kind: Pod
metadata:
 name: kafka-client
 namespace: default
spec:
 containers:
 - name: kafka-client
   image: confluentinc/cp-kafka:5.0.1
   command:
     - sh
     - -c
     - "exec tail -f /dev/null"
---
#after deployment file is ready
<while being in kafka-client directory

$kubectl apply -f deployment.yaml

#Login into kafka-client pod
$ kubectl exec -it kafka-client -- /bin/bash
root@kafka-client:/# kafka-topics --zookeeper zookeeper-client:2181 --topic topic1 
--create --partitions 1 --replication-factor 1 --if-not-exists
Created topic "topic1"

#creating a message
root@kafka-client:/# TEXT="hello world !"

#Producing a message to topic
root@kafka-client:/# echo $TEXT | kafka-console-producer 
   --broker-list kafka-xxxxx:9092 --topic topic1

#consuming messages
root@kafka-client:/# kafka-console-consumer --bootstrap-server kafka-xxxxx:9092 --topic 
topic1 --from-beginning --timeout-ms 2000 --max-messages 1 | grep "$TEXT"

--Additional: To stop and start PODS
$ kubectl get deployments | awk {'print $1" "$5'} | column -t
NAME                                          AGE
cp-helm-charts-1628681515-cp-control-center   102m
cp-helm-charts-1628681515-cp-kafka-connect    102m
cp-helm-charts-1628681515-cp-kafka-rest       102m
cp-helm-charts-1628681515-cp-ksql-server      102m
cp-helm-charts-1628681515-cp-schema-registry  102m
zookeeper-1                                   154m

ajuser:~/environment $ kubectl scale deploy cp-helm-charts-1628681515-cp-kafka-connect --replicas=0
deployment.apps/cp-helm-charts-1628681515-cp-kafka-connect scaled

ajuser:~/environment $ kubectl scale deploy cp-helm-charts-1628681515-cp-kafka-rest --replicas=0
deployment.apps/cp-helm-charts-1628681515-cp-kafka-rest scaled

ajuser:~/environment $ kubectl scale deploy cp-helm-charts-1628681515-cp-ksql-server --replicas=0
deployment.apps/cp-helm-charts-1628681515-cp-ksql-server scaled

ajuser:~/environment $ kubectl scale deploy cp-helm-charts-1628681515-cp-schema-registry --replicas=0
deployment.apps/cp-helm-charts-1628681515-cp-schema-registry scaled

ajuser:~/environment $ kubectl get pods

#start pods
ajuser:~/environment $ kubectl scale deploy cp-helm-charts-1628681515-cp-kafka-rest --replicas=1
and so on..

#deleting a pod
ajuser:~/environment $ kubectl delete pod zookeeper-1-6747f5b7cc-24z4p
---

cleanup:
To remove the pods, list the pods with kubectl get pods and then delete the pods by name.

kubectl get pods
kubectl delete pod <podname>
To delete the Helm release, find the Helm release name with helm list and delete it with helm delete.
 You may also need to clean up leftover StatefulSets, since helm delete can leave them behind. Finally, clean up all persisted volume claims (pvc) created by this release.

helm list
helm delete <release name>
kubectl delete statefulset <release name>-cp-kafka <release name>-cp-zookeeper
kubectl delete pvc --selector=release=<release name>




